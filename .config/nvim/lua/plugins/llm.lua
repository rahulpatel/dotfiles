return {
  -- "huggingface/llm.nvim",
  -- opts = {
  --   backend = "ollama",
  --   model = "starcoder2:15b",
  --   url = "http://192.168.1.201:11434", -- llm-ls uses "/api/generate"
  --   tokens_to_clear = { "<|endoftext|>" },
  --   fim = {
  --     enabled = true,
  --     prefix = "<fim_prefix>",
  --     middle = "<fim_middle>",
  --     suffix = "<fim_suffix>",
  --   },
  --   context_window = 8192,
  --   lsp = {
  --     bin_path = vim.api.nvim_call_function("stdpath", { "data" }) .. "/mason/bin/llm-ls",
  --   },
  -- },
}
